{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with minibatch gradient descent and saving logs for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling data (important in case of gradient descent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  6.60969987e-17,  5.50808322e-18,  6.60969987e-17,\n",
       "       -1.06030602e-16, -1.10161664e-17,  3.44255201e-18, -1.07958431e-15,\n",
       "       -8.52651283e-15])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n=housing.data.shape\n",
    "stdsc=StandardScaler()\n",
    "scaled_housing=stdsc.fit_transform(housing.data)\n",
    "scaled_housing_plus_bias=np.c_[np.ones([m,1]),scaled_housing]\n",
    "\n",
    "scaled_housing_plus_bias.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batchsize and number of batches to be processed in one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize=100\n",
    "n_batches=np.ceil(m/batchsize).astype(int)\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for selection of a batch and parsing X, y:\n",
    "- in contrast to experiment3_minibatch_gradient_descent.ipynb notebook we do not fix the random seed, in order to get different results in different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_minibatch(epoch, batch_index, batch_size):\n",
    "    #np.random.seed(epoch*n_batches+batch_index)\n",
    "    #print(epoch*n_batches+batch_index)\n",
    "    indices=np.random.randint(m, size=batch_size)\n",
    "    X=scaled_housing_plus_bias[indices]\n",
    "    y=housing.target[indices]\n",
    "    #print(indices)\n",
    "    return X,y\n",
    "\n",
    "X,y=select_minibatch(1, batchsize, 5)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational graph of one gradient descent step:\n",
    "- in contrast to experiment3_minibatch_gradient_descent.ipynb notebook we do not set random seed=42 here, to get different results in different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder nodes for X and y:\n",
    "X=tf.placeholder(shape=(None,n+1), dtype=tf.float32, name='X') \n",
    "y=tf.placeholder(shape=(None,1), dtype=tf.float32, name='y')\n",
    "\n",
    "# variable node: coefficients theta with random initialization:\n",
    "#tf.set_random_seed(42)\n",
    "theta=tf.Variable(tf.random_uniform((n + 1, 1), -1.0, 1.0),name='Theta') #we did not set random seed=42 here\n",
    "\n",
    "# nodes for computing mse:\n",
    "error=y-tf.matmul(X,theta)\n",
    "mse=tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "lerr=0.01 #learning rate\n",
    "# gradient descent optimizer object: \n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=lerr)\n",
    "# operation for gradient descent of mse (probably doing gradient descent in all variables)\n",
    "training_op=optimizer.minimize(mse, name=\"Training_op\")\n",
    "# saver object\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "#variable initializer object: \n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding nodes & objects to save logs for Tensorboard to graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "root_logdir=\"linreg_logs\"\n",
    "logdir=\"{}/run-{}/\".format(root_logdir, now)\n",
    "# logdir2=root_logdir+'/run-'+str(now)+'/'\n",
    "\n",
    "# node for evaluating mse and outputing it in tensorboard-readable string:\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "# object that can write summaries into logfile\n",
    "file_writer=tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types (ops for operation => operation node). optimizer is not a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.framework.ops.Tensor,\n",
       " tensorflow.python.framework.ops.Tensor,\n",
       " tensorflow.python.ops.variables.Variable,\n",
       " tensorflow.python.framework.ops.Operation,\n",
       " tensorflow.python.training.gradient_descent.GradientDescentOptimizer,\n",
       " tensorflow.python.training.saver.Saver,\n",
       " tensorflow.python.framework.ops.Tensor,\n",
       " tensorflow.python.summary.writer.writer.FileWriter)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(mse), type(theta), type(training_op), type(optimizer), type(saver),\\\n",
    "type(mse_summary), type(file_writer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ops currently in the graph. note that constructing GradientDescentOptimizer and Saver instances addedmany nodes with names:\n",
    "- gradients/*\n",
    "- GradientDescent*\n",
    "- save/*\n",
    "\n",
    "also note that there is no node with name error: the computation of error is splitted intu MatMul and sub nodes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gf=tf.get_default_graph()\n",
    "len(gf.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of the computational graph (number of tensors, these are represented as nodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf=tf.get_default_graph()\n",
    "len(gf.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing gradient descent step graph several times updating the variable theta. \n",
    "- In every 10th step, MSE is written into logfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    #print(theta.eval())\n",
    "    n_epochs=10\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            Xb,yb=select_minibatch(epoch, batch_index, batchsize)\n",
    "            #writing log for tensorboard\n",
    "            if batch_index % 10 ==0:\n",
    "                summary_str=mse_summary.eval(feed_dict={X:Xb, y:yb.reshape(-1,1)})\n",
    "                step=epoch*n_batches+batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X:Xb, y:yb.reshape(-1,1)})\n",
    "    best_theta=theta.eval()\n",
    "    saver.save(sess, \"./saved_models/final_minibatch.ckpt\")\n",
    "    # important to close in order to be able to directly see the results in the tensorboard:\n",
    "    file_writer.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimal theta for the scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.063703  ],\n",
       "       [ 0.8634768 ],\n",
       "       [ 0.12174791],\n",
       "       [-0.33336237],\n",
       "       [ 0.31161296],\n",
       "       [-0.0083907 ],\n",
       "       [-0.03535056],\n",
       "       [-0.7775841 ],\n",
       "       [-0.7454997 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_graph_in_jupyter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f90d85f98499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_graph_in_jupyter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_graph_in_jupyter'"
     ]
    }
   ],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
